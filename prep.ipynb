{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import weight_norm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "from scipy.interpolate import spline\n",
    "\n",
    "#read each csv in the train directory, stack them into two numpy matrices. \n",
    "#One with the readings from the EEG (self.data) and one with the corresponding class labels (self.target)\n",
    "\n",
    "class eegdata(Dataset):\n",
    "    \n",
    "    def __init__(self, path, validation=False, subjects=range(1,13)):\n",
    "        super().__init__()\n",
    "        data, self.target = self.readfiles(path, validation, subjects)\n",
    "        self.mean= data.mean(axis=0)\n",
    "        self.std = data.std(axis=0)\n",
    "        self.data = self.norm(data)\n",
    "    \n",
    "    def norm(self, x):\n",
    "        return ((x - self.mean)/self.std)\n",
    "    \n",
    "    def to_np(self, values):\n",
    "        \n",
    "        #get total lines of data count\n",
    "        count = 0\n",
    "        for i in range(len(values)):\n",
    "            count += len(values[i])\n",
    "        \n",
    "        #create np array size of all data\n",
    "        ret = np.zeros((count, len(values[0][0])))\n",
    "        \n",
    "        #copy data into np array \n",
    "        ix = 0\n",
    "        for i in range(len(values)):\n",
    "            ret[ix:ix+len(values[i]), :] = values[i]\n",
    "            ix += len(values[i])\n",
    "        return ret\n",
    "        \n",
    "    \n",
    "    def readfiles(self, path, validation, subjects):\n",
    "        \n",
    "        allx = []\n",
    "        ally = []\n",
    "        \n",
    "        series = [1,2,4,5,6,7,8] if validation == False else [3]\n",
    "        \n",
    "        for i in subjects:\n",
    "            print('log: reading subject {}...'.format(i))\n",
    "            xs = None\n",
    "            ys = None\n",
    "            for j in series:\n",
    "\n",
    "                data = 'subj{}_series{}_data.csv'.format(i,j)\n",
    "                events = 'subj{}_series{}_events.csv'.format(i,j)\n",
    "\n",
    "                x = pd.read_csv(path + data).values[:, 1:]\n",
    "                xs = x if xs is None else np.vstack((xs, x))\n",
    "\n",
    "                y = pd.read_csv(path + events).values[:, 1:]\n",
    "                ys = y if ys is None else np.vstack((ys, y))\n",
    "\n",
    "            allx.append(xs)\n",
    "            ally.append(ys)\n",
    "\n",
    "        xs = self.to_np(allx)\n",
    "        ys = self.to_np(ally)\n",
    "\n",
    "        return xs, ys\n",
    "                    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.target[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "#put all the subjects data into one big array\n",
    "traindata = eegdata('./train/')\n",
    "valdata = eegdata('./train/', validation=True)\n",
    "\n",
    "# also create individual datasets for subjects\n",
    "def get_individuals():\n",
    "          \n",
    "    subjects = []\n",
    "    vals = []\n",
    "\n",
    "    for i in range(1,13):\n",
    "    \n",
    "        s = [i]\n",
    "        subject = eegdata('./train/', subjects=s) #yes?\n",
    "        v = eegdata('./train/', validation=True, subjects=s)\n",
    "        subjects.append(subject)\n",
    "        vals.append(v)\n",
    "        \n",
    "    return subjects, vals\n",
    "\n",
    "subjects, vals = get_individuals()\n",
    "\n",
    "# function to see how readings change on average over course of an event\n",
    "def get_spike(subject, event, average=True):\n",
    "    \n",
    "    spike = np.zeros([19,32])\n",
    "    s = subject\n",
    "\n",
    "    indexes = np.where(subjects[s].target[:,event] == 1)[0]\n",
    "    i = 0\n",
    "    div = 0\n",
    "    \n",
    "    while i < len(indexes):\n",
    "        \n",
    "        ix = subjects[s].data[indexes[i]-100:indexes[i+149]+50] #it works!\n",
    "        spike += ix[::16]\n",
    "        div += 1\n",
    "        i += 150\n",
    "\n",
    "    spike /= div\n",
    "    if average == True:\n",
    "        spike = spike.mean(axis=1)\n",
    "    return spike\n",
    "\n",
    "# plot figures for how readings change across all 12 subjects for 'HandStart' action\n",
    "fig = plt.figure(12, figsize=[10,10])\n",
    "for s in range(12):\n",
    "    \n",
    "    ax = fig.add_subplot(3,4,s+1)\n",
    "    spike = get_spike(s, 0)\n",
    "    xnew = np.linspace(0,len(spike),19) #300 represents number of points to make between T.min and T.max\n",
    "\n",
    "    smooth = spline(xnew,spike,xnew)\n",
    "    ax.plot(range(len(spike)), spike)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    \n",
    "# ignore depreacted spline warning stuff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
